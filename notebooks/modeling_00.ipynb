{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7670e4fb-b22f-47e5-ab9f-10d7760c3b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import PIL\n",
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "\n",
    "PIL.ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ddbd53-f3bb-4193-954f-d51547502fde",
   "metadata": {},
   "source": [
    "## Initializing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cba9a66-6a9f-4a9f-9235-bb6e046dc390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories\n",
    "train_dir = '../data/train'\n",
    "valid_dir = '../data/valid'\n",
    "test_dir = '../data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9fd16fd-03fa-458a-a392-50810079ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)), # resizes to 64x64\n",
    "    transforms.ToTensor(),   # convert image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f511a1-4f1e-4237-85c9-d7801aa2d171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes dataset from training directory\n",
    "train_dataset = ImageFolder(root=train_dir, transform = img_transform)\n",
    "valid_dataset = ImageFolder(root=valid_dir, transform = img_transform)\n",
    "\n",
    "\n",
    "# creates dataloader over dataset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 16, shuffle = True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = 16, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be07ca4-8e65-4255-b4c5-4482c2ecdd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 64, 64]) tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_dataloader)\n",
    "images, labels = next(data_iter)\n",
    "print(images.shape, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e0a6a4-68f7-4b64-a0d5-bc06e64609a6",
   "metadata": {},
   "source": [
    "## First Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7917853-ba30-4472-9aa2-86a3cab6c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size = 3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(16, 32, kernel_size = 3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32*16*16, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9af8fbe-1059-43d6-9649-930ef29e4357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=8192, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (10): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73b67031-4cb2-4c0b-8911-6fcc7fc88c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=8192, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (10): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "criterion = nn.BCELoss()  # Loss function for classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Optimizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20954c14-5e1b-4b11-a713-bfe12c4155dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch}/{num_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(images).squeeze()  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        predicted = (outputs > 0.5).float()  # Convert to 0 or 1 based on threshold\n",
    "        correct += (predicted.squeeze() == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    accuracy = 100 * correct / total\n",
    "    #print(f\"Train Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55bdd8db-14bb-4166-85cb-a8d6edd428f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|████████████████████████████| 1891/1891 [00:48<00:00, 38.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1553, Train Accuracy: 94.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|████████████████████████████| 1891/1891 [00:51<00:00, 36.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1321, Train Accuracy: 95.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|████████████████████████████| 1891/1891 [00:51<00:00, 36.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1128, Train Accuracy: 95.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|████████████████████████████| 1891/1891 [00:52<00:00, 36.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0899, Train Accuracy: 96.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|████████████████████████████| 1891/1891 [00:52<00:00, 36.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0691, Train Accuracy: 97.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_one_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33bd6044-b46e-4e4e-9de2-9ee9744f4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/test_model_00.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33a908-b533-4e5e-9256-6efa019d80d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
